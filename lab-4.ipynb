{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f20ccea4-1ef0-4f90-a0c3-3cbe1b0f7adc",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "\n",
    "## Data wrangling and transformation\n",
    "\n",
    "Often, datasets need to go through a series of data wrangling and transformation steps before they are ready for analysis or visualisation tasks. This lab will demonstrate several data wrangling and transformation operations for raster, vector, and tabular data. \n",
    "\n",
    "We will start with a subset of the AgriFieldNet Competition Dataset <a href=\"https://mlhub.earth/data/ref_agrifieldnet_competition_v1\" target=\"_blank\">(Radiant Earth Foundation and IDinsight, 2022)</a> which has been published to encourage people to develop machine learning models that classify a field's crop type from satellite images. This dataset consists of a series of directories with each directory corresponding to a 256 x 256 pixel image footprint. Inside each directory are the following files:\n",
    "\n",
    "* 12 GeoTIFF files corresponding to spectral reflectance in different wavelengths from Sentinel-2 data. \n",
    "* 1 GeoTIFF file with non-zero pixels corresponding to a crop type label. \n",
    "* 1 GeoTIFF file with non-zero pixels corresponding to a field id. \n",
    "* 1 JSON metadata file. \n",
    "\n",
    "This data is subset from a larger dataset covering agricultural fields in four Indian states: Odisha, Uttar Pradesh, Bihar, and Rajasthan. The field boundaries and crop type labels were captured by data collectors from IDinsight's Data on Demand team and the satellite image preparation was undertaken by the Radiant Earth Foundation. \n",
    "\n",
    "### Task\n",
    "\n",
    "Our task is to combine all the raster data in a folder into a tabular dataset that can be used for machine learning tasks to predict a field's crop type. Specifically, we will  transform a collection of GeoTiff files into a tabular dataset with columns for each field id, crop type, and field average spectral reflectance values. We will also store geometry data representing the location of each field in a geometry column. \n",
    "\n",
    "![](https://github.com/data-analysis-3300-3003/figs/raw/main/week-4-overview.jpg)\n",
    "\n",
    "You will learn a range of common data transformation operations to wrangle datasets into a structure suitable for analysis and visualisation.  \n",
    "\n",
    "**This lab will focus on transformation operations applied to raster data.** This lab will cover:\n",
    "\n",
    "* **attribute operations:** subsetting rasters.\n",
    "* **attribute operations:** band stacking to create multiband rasters.\n",
    "* **attribute operations:** reshaping multiband rasters.\n",
    "* **spatial data operations:** local map algebra operations to mathematically combine rasters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dfa67c-251e-47c3-8986-8c7285721ab2",
   "metadata": {},
   "source": [
    "### What is data wrangling?\n",
    "\n",
    "<a href=\"https://r4ds.had.co.nz/wrangle-intro.html\" target=\"_blank\">Wickham and Grolemund (2017)</a> and <a href=\"https://wesmckinney.com/book/\" target=\"_blank\">McKinney (2022)</a> state that data wrangling consists of data import, data cleaning, and data transformation. \n",
    "\n",
    "#### Data import\n",
    "\n",
    "Data import was covered in week 2 with examples of how to read tabular, vector, and raster data into Python programs. \n",
    "\n",
    "#### Data cleaning\n",
    "\n",
    "Data cleaning was covered in week 3 as part of the exploratory data analysis with examples of how to handle outliers and missing data. \n",
    "\n",
    "#### Data transformation\n",
    "\n",
    "<a href=\"https://wesmckinney.com/book/\" target=\"_blank\">McKinney (2022)</a> define data transformation as the application of mathematical or statistical operations to data to generate new datasets. Data transformation can also include operations that reshape datasets or combine two or more datasets.\n",
    "\n",
    "<details>\n",
    "    <summary><b>Detailed notes on data transformation for spatial and non-spatial data</b></summary>\n",
    "As we're working with spatial and non-spatial data we can categorise data transformation operations as attribute operations, spatial operations, geometry operations, and raster-vector  operations (<a href=\"https://geocompr.robinlovelace.net/index.html\" target=\"_blank\">Lovelace et al. (2022)</a>).\n",
    "    \n",
    "**Attribute operations** are applied to non-spatial (attribute data). This could be a tabular dataset without any spatial information, the attribute table of a vector dataset, or the pixel values of a raster dataset. Common attribute operations include:\n",
    "\n",
    "* Selecting columns from a table based on a condition. \n",
    "* Selecting (subsetting) pixels from a raster based on a condition.\n",
    "* Filtering rows from a table based on a condition. \n",
    "* Creating a new column of values using a function applied to existing data.\n",
    "* Computing summary statistics of columns in a table or of pixel values in a raster.\n",
    "* Joining datasets based on matching values in columns (keys).\n",
    "\n",
    "**Spatial operations** transform data using the data's geographic information including shape and location. Vector spatial operations include:\n",
    "\n",
    "* Spatial subsetting by selecting data points based on a geographic condition (e.g. selecting all fields in Western Australia).\n",
    "* Spatial joins where datasets are combined based on their relationship in space. \n",
    "* Spatial aggregation where summaries are produced for regions (e.g. the average crop yield for all fields in a region).\n",
    "\n",
    "Spatial operations on raster data are based on map algebra concepts and include:\n",
    "\n",
    "* Local operations which are applied on a pixel by pixel basis (e.g. converting a raster of temperature values in °F to °C).\n",
    "* Focal operations which summarise or transform a raster value using the values of neihbouring pixels (e.g. computing the average value within a 3 x 3 pixel moving window).\n",
    "* Zonal operations which summarise or transform raster values using values inside an irregular shaped zone.\n",
    "* Global operations which summarise the entire raster (e.g. computing the minimum value in the raster dataset). \n",
    "\n",
    "**Geometry operations** transform a dataset's geographic information. Common geometry operations for vector data include:\n",
    "\n",
    "* Simplification of shapes.\n",
    "* Computing the centroid of polygons.\n",
    "* Clipping (subsetting) of geometries based on their intersection or relationship with another geometry. \n",
    "\n",
    "and geometry operations on raster data typically involve changing the spatial resolution and include:\n",
    "\n",
    "* Aggregation or dissagregation.\n",
    "* Resampling.\n",
    "\n",
    "**Raster-vector operations** involve both raster and vector datasets and include:\n",
    "\n",
    "* Cropping or masking raster data using a vector geometry.\n",
    "* Extracting raster values that intersect with a vector geometry.\n",
    "* Rasterisation where a vector dataset is transformed to a raster layer.\n",
    "* Vectorisation where a raster dataset is transformed to a vector layer.\n",
    "</details>\n",
    "\n",
    "\n",
    "### Feature engineering\n",
    "\n",
    "Feature engineering is part of a machine learning workflow which involves preparing and preprocessing datasets ready for machine learning model training and evaluation. Feature engineering is one example where data wrangling operations are applied. This lab can be considered a feature engineering task where a range of raster satellite image datasets are transformed to a vector-tabular dataset which can be used to train and test a machine learning model. Often, datasets for machine learning computer vision tasks (e.g. see the datasets on Radiant Earth's <a href=\"https://mlhub.earth/\" target=\"_blank\">MLHub</a>) are provided with data samples for model development spread across many sub-directories. Prior to model training you need to extract the data from these directories and assemble it in a way that it can be passed into a model. You can use this lab as a starter template for these kind of feature engineering tasks.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f2b402-819a-47b4-a1d2-0d0e2209a220",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Run the labs\n",
    "\n",
    "You can run the labs locally on your machine or you can use cloud environments provided by Google Colab. **If you're working with Google Colab be aware that your sessions are temporary and you'll need to take care to save, backup, and download your work.**\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/data-analysis-3300-3003/colab/blob/main/lab-4.ipynb\" target=\"_blank\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "### Download data\n",
    "\n",
    "If you need to download the data for this lab, run the following code snippet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6417f87-ebf2-4955-b593-5e2ccc7748ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if \"week-4\" not in os.listdir(os.getcwd()):\n",
    "    os.system('wget \"https://github.com/data-analysis-3300-3003/data/raw/main/data/week-4.zip\"')\n",
    "    os.system('unzip \"week-4.zip\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c646b92f-1966-4904-b221-f4715630f341",
   "metadata": {},
   "source": [
    "### Working in Colab\n",
    "\n",
    "If you're working in Google Colab, you'll need to install the required packages that don't come with the colab environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e478e4-615a-4713-bae1-75cd440e48b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    !pip install geopandas\n",
    "    !pip install pyarrow\n",
    "    !pip install mapclassify\n",
    "    !pip install rasterio\n",
    "    !pip install libpysal\n",
    "    !pip install esda\n",
    "    !pip install splot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf742d0-c865-4407-9551-b35cd21a6774",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31e0488-dedf-4e03-9cb3-363cffec6b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "import plotly.io as pio\n",
    "import shapely.geometry\n",
    "import pprint\n",
    "\n",
    "from rasterio import features\n",
    "\n",
    "# setup renderer\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    pio.renderers.default = \"colab\"\n",
    "else:\n",
    "    pio.renderers.default = \"jupyterlab\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283743b5-18c6-4260-8569-a8e838bc932b",
   "metadata": {},
   "source": [
    "## Data storage\n",
    "\n",
    "In week 2 we showed that files are organised within a hierarchy of directories and sub-directories (or folders) in a computer system. Here, each sample (a 256 x 256 pixel image footprint) is stored in its own sub-directory. We can explore the structure of these directories and how files are arranged within them. \n",
    "\n",
    "First, let's list the first level of sub-directories within the `week-4` folder. Each of these sub-directories corresponds to a 256 x 256 pixel image.\n",
    "\n",
    "To recap, we can use functions provided by the `os` package to help us explore directories. The `os.path.join()` function takes a sequence of string data representing directory names or file names and combines them into a path. The `os.listdir()` function lists all files or sub-directories in a directory pointed to by a path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d62be97-a8fe-41f5-a600-5d4108c45164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image and labels data\n",
    "data_path = os.path.join(os.getcwd(), \"week-4\", \"images\")\n",
    "\n",
    "image_dirs = os.listdir(data_path)\n",
    "for i in image_dirs:\n",
    "    if i != \".DS_Store\":\n",
    "        print(i)\n",
    "    \n",
    "if \".DS_Store\" in image_dirs:\n",
    "    image_dirs.remove(\".DS_Store\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5be2da-de7e-4f00-b733-bcd66fd7b947",
   "metadata": {},
   "source": [
    "The `os.listdir()` function lists files or directories at the first level of the directory passed into the function. However, often we have nested directory structures consisting of a hierarchy of sub-directories and files. The `os.walk()` can be used to traverse a directory tree. We can use the `os.walk()` function to fully reveal how the files are arranged within a sub-directory. \n",
    "\n",
    "We can see that within each sub-directory corresponding to a 256 x 256 pixel image footprint there are the following files and sub-directories:\n",
    "\n",
    "* Files with the names `B*.tif` which are Sentinel-2 images for a particular waveband. For example, B02.tif is Sentinel-2 reflectance in the blue visible wavelength. These files will be used to generate predictor variables in a subsequent machine learning task to predict crop type.\n",
    "* A `field` sub-directory which contains a `field_ids.tif` file. This file stores field ids as pixel values. \n",
    "* A `label` sub-directory which contains a `raster_labels.tif` file. This file stores a numeric indicator of crop type as pixel values. These files store target labels used to train and test a machine learning model that predicts crop type from spectral reflectance data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2c9737-4b9f-4945-96fc-5c16b554bfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(os.path.join(data_path, image_dirs[1]), topdown=True):\n",
    "    print(root)\n",
    "    for f in files:\n",
    "        print(f\"    {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2814e3b5-00a1-4d2a-a712-b09a2661ba87",
   "metadata": {},
   "source": [
    "### Data visualisation\n",
    "\n",
    "Let's quickly visualise some of this data to get an idea of its structure. First, let's visualise the Sentinel-2 satellite image data starting with the image storing reflectance in the green visible portion of the electromagnetic spectrum. \n",
    "\n",
    "We can see that the image shape is 256 x 256 pixels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832252ac-4328-4ae8-97ba-6a6ea9c6ea73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the green band GeoTIFF file\n",
    "s2_green_path = os.path.join(os.getcwd(), \"week-4\", \"images\", \"ref_agrifieldnet_competition_v1_source_0a664\", \"B03.tif\")\n",
    "\n",
    "# open the green band GeoTIFF file and read its image data\n",
    "with rasterio.open(s2_green_path) as src:\n",
    "    green_band = src.read(1)\n",
    "    print(f\"the shape of the image is {green_band.shape}\")\n",
    "\n",
    "# plot the green band\n",
    "px.imshow(green_band, color_continuous_scale=\"Greens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d8b127-fa99-446a-b700-e988d7cfcbfe",
   "metadata": {},
   "source": [
    "Let's also create a true colour composite image using the red, green, and blue band images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a566df4e-be56-4c1f-bcc0-a02d78800c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the red band GeoTIFF file\n",
    "s2_red_path = os.path.join(os.getcwd(), \"week-4\", \"images\", \"ref_agrifieldnet_competition_v1_source_0a664\", \"B04.tif\")\n",
    "\n",
    "# open the red band GeoTIFF file and read its image data\n",
    "with rasterio.open(s2_red_path) as src:\n",
    "    red_band = src.read()\n",
    "\n",
    "# path to the green band GeoTIFF file\n",
    "s2_green_path = os.path.join(os.getcwd(), \"week-4\", \"images\", \"ref_agrifieldnet_competition_v1_source_0a664\", \"B03.tif\")\n",
    "\n",
    "# open the green band GeoTIFF file and read its image data\n",
    "with rasterio.open(s2_green_path) as src:\n",
    "    green_band = src.read()\n",
    "    \n",
    "# path to the blue band GeoTIFF file\n",
    "s2_blue_path = os.path.join(os.getcwd(), \"week-4\", \"images\", \"ref_agrifieldnet_competition_v1_source_0a664\", \"B02.tif\")\n",
    "\n",
    "# open the blue band GeoTIFF file and read its image data\n",
    "with rasterio.open(s2_blue_path) as src:\n",
    "    blue_band = src.read()\n",
    "    \n",
    "# make RGB image\n",
    "rgb = np.concatenate((red_band, green_band, blue_band), axis=0)\n",
    "\n",
    "# plot the rgb image\n",
    "px.imshow(np.moveaxis(rgb, 0, 2), contrast_rescaling=\"minmax\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1593d746-a3f9-4bab-a4fb-1e4ebade72b2",
   "metadata": {},
   "source": [
    "Now, let's explore the field id images. We can see that the image contains a few fields with ids assigned to them. Hover over each field and you can see its numeric id value. However, we can also see that a large portion of the image is covered by pixels with the value 0. These locations are not labelled fields and we will need to drop them from our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2272cb08-549a-4532-b5a7-abc5e7b9dd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the GeoTIFF file\n",
    "field_id_path = os.path.join(os.getcwd(), \"week-4\", \"images\", \"ref_agrifieldnet_competition_v1_source_0a664\", \"field/field_ids.tif\")\n",
    "\n",
    "# open the GeoTIFF file and read its image data\n",
    "with rasterio.open(field_id_path) as src:\n",
    "    field_id_band = src.read(1)\n",
    "\n",
    "# plot the field id band\n",
    "px.imshow(field_id_band, color_continuous_scale=[\"#ffffff\", \"#1b9e77\", \"#d95f02\", \"#7570b3\", \"#e7298a\", \"#66a61e\", \"#e6ab02\", \"#a6761d\", \"#666666\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922511ff-ba68-4b45-a75e-1ddf4012f321",
   "metadata": {},
   "source": [
    "Finally, we can look at our labels image. Each field's pixels are assigned a numeric value that corresponds to a crop type. Based on the dataset's documentation, this is the mapping between numeric values and crop types in the labels dataset. \n",
    "\n",
    "* 1 - Wheat\n",
    "* 2 - Mustard\n",
    "* 3 - Lentil\n",
    "* 4 - No crop/Fallow\n",
    "* 5 - Green pea\n",
    "* 6 - Sugarcane\n",
    "* 8 - Garlic\n",
    "* 9 - Maize\n",
    "* 13 - Gram\n",
    "* 14 - Coriander\n",
    "* 15 - Potato\n",
    "* 16 - Bersem\n",
    "* 36 - Rice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66c7454-26b3-4dec-97b0-7a3d5a27d334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the GeoTIFF file\n",
    "label_path = os.path.join(os.getcwd(), \"week-4\", \"images\", image_dirs[1], \"label/raster_labels.tif\")\n",
    "\n",
    "# open the GeoTIFF file and read its metadata and image data\n",
    "with rasterio.open(label_path) as src:\n",
    "    label_band = src.read(1)\n",
    "\n",
    "# Plot the crop label band\n",
    "px.imshow(label_band, color_continuous_scale=[\"#ffffff\", \"#1b9e77\", \"#d95f02\", \"#7570b3\", \"#e7298a\", \"#66a61e\", \"#e6ab02\", \"#a6761d\", \"#666666\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6a3c0f-24a2-4384-a55d-14a9c78c4f6a",
   "metadata": {},
   "source": [
    "## Raster data processing\n",
    "\n",
    "### NumPy refresher\n",
    "\n",
    "In week 2 we introduced NumPy `ndarray` objects for storing multidimensional (or N-dimensional) arrays which consist of a grid of elements of the same data type. `ndarray` objects are a logical data structure for representing and manipulating raster and image data in Python programs.\n",
    "\n",
    "The dimensions of a NumPy `ndarray` are called axes. A single band raster layer would have two axes, rows (height) would be arranged along the 0th axis and columns (width) along the 1st axis. The shape of an `ndarray` refers to the number of elements along each axis. \n",
    "\n",
    "Let's quickly revise these concepts by working with a raster layer with 3 rows and 3 columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211505b1-6ac5-4846-a742-facadbb3b235",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_raster = np.array(\n",
    "    [[1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9]])\n",
    "print(demo_raster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19277458-33c6-4319-bf46-28a3045127f3",
   "metadata": {},
   "source": [
    "This `ndarray` object should have 2 axes corresponding to rows (0 axis) and columns (1 axis) with 3 elements along each axis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c36ea21-4ca3-491b-97ed-c9a50c6a2e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"the shape of demo_raster is {demo_raster.shape}\")\n",
    "print(f\"the number of elements on the 0 axis (rows) is {demo_raster.shape[0]}\")\n",
    "print(f\"the number of elements on the 1 axis (columns) is {demo_raster.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e200f323-7125-4f5b-b999-9ea7d5b38337",
   "metadata": {},
   "source": [
    "### Subsetting NumPy `ndarray`s\n",
    "\n",
    "This is a form of subsetting opertation where you select values from a NumPy `ndarray` object based on their index locations. These operations are generally referred to as **indexing** and **slicing** when working with NumPy `ndarray` objects. <a href=\"https://geocompr.robinlovelace.net/index.html\" target=\"_blank\">Lovelace et al. (2022)</a> refer to these operations on raster data as *row-column subsetting*.\n",
    "\n",
    "![](https://github.com/data-analysis-3300-3003/figs/raw/main/week-4-subset-numpy-ndarray.jpg)\n",
    "\n",
    "We can extract a value from a NumPy `ndarray` based on its index location. For example, the first element of a 2-Dimensional `ndarray` is at location `[0, 0]` (i.e. the 0th row and 0th column). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b295b3-f05f-4020-b32a-95ff8b922c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_element = demo_raster[0, 0]\n",
    "print(first_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3216fb93-870a-467c-989b-2c40b844949d",
   "metadata": {},
   "source": [
    "We can use the `:` symbol to specify slices of a NumPy `ndarray` to subset. For example, the following are three different ways of slicing the first two rows.\n",
    "\n",
    "Note that the slice is not inclusive of the index location after the `:` symbol. So, `demo_raster[0:2, ]` would select the first two rows of `demo_raster` - row 0 and row 1 (remember Python indexes from 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da4de28-d13f-4041-bc33-42194bf2c381",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_rows_1 = demo_raster[0:2, ]\n",
    "print(two_rows_1)\n",
    "\n",
    "two_rows_2 = demo_raster[0:2]\n",
    "print(two_rows_2)\n",
    "\n",
    "two_rows_3 = demo_raster[:2]\n",
    "print(two_rows_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce22181-f234-44d4-ae8d-163a40eb3099",
   "metadata": {},
   "source": [
    "We can use multiple slices for different axes. For example, if we wanted to subset values from a selection of rows and columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fd2c7e-6b80-4552-8a7d-f5c7ea6ee3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_rows_cols = demo_raster[:2, 1:]\n",
    "print(two_rows_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27edc694-f104-4b4b-be91-5099951ac543",
   "metadata": {},
   "source": [
    "### Band stacking \n",
    "\n",
    "A common data wrangling and combination operation when working with raster data is band stacking. This is the process of taking two or more single band rasters and stacking them to create a multiband raster. \n",
    "\n",
    "When using NumPy `ndarray` objects to handle raster data, this process could involve stacking two `ndarray` objects with a shape of `(256, 256)` to create a new `ndarray` object with the shape `(2, 256, 256)`. Here, axis 0 has a length of two which indicates that we've stacked two `ndarray` objects with the shape `(256, 256)`.\n",
    "\n",
    "We can use the NumPy `stack()` or `concatenate()` functions to combine a sequence of `ndarray`s along an axis. \n",
    "\n",
    "We can write a short code snippet to start our data transformation program that will loop over Sentinel-2 bands, read the data stored in GeoTIFF files corresponding to Sentinel-2 reflectance values (bands) into an `ndarray`, and then use <a href=\"https://numpy.org/doc/stable/reference/generated/numpy.stack.html\" target=\"_blank\">NumPy's `stack()`</a> function to stack a list of `ndarray`s to represent a multiband raster structure.\n",
    "\n",
    "![](https://github.com/data-analysis-3300-3003/figs/raw/main/week-4-band-stacking-single-dir.jpg)\n",
    "\n",
    "<details>\n",
    "    <summary><b>Detailed step-by-step notes on the band stacking routine</b></summary>\n",
    "\n",
    "Create an empty list which we'll use to store <code>ndarray</code> objects of data read from the <code>B*.tif</code> GeoTIFF files. This is defined as <code>bands = []</code>, the <code>[]</code> creates an empty list:\n",
    "\n",
    "```{python}\n",
    "# empty list to append ndarray of reflectance value for each band to\n",
    "bands = []\n",
    "```\n",
    "<p></p>\n",
    "\n",
    "Now, iterate over the list of band names referenced by <code>s2_bands</code> and for each band read the data stored in the corresponding <code>B*.tif</code> file into a <code>ndarray</code> and append the <code>ndarray</code> to the <code>bands</code> list using the <code>bands.append(src.read(1))</code> command. \n",
    "\n",
    "```{python}\n",
    "# loop over each band, read in the data from the corresponding GeoTIFF file into an ndarray\n",
    "for b in s2_bands:\n",
    "    band_path = os.path.join(image_dir_path, b + \".tif\")\n",
    "    with rasterio.open(band_path) as src:\n",
    "        # append the ndarray storing the Sentinel-2 reflectance data for a band to a list\n",
    "        bands.append(src.read(1))\n",
    "```\n",
    "<p></p>\n",
    "\n",
    "You will notice the use of the context manager denoted by the <code>with</code> block to read data from GeoTIFF files into a NumPy <code>ndarray</code>. This was covered in week 2, but let's revise this quickly: \n",
    "\n",
    "```{python}\n",
    "with rasterio.open(band_path) as src:\n",
    "```\n",
    "<p></p>\n",
    "\n",
    "Creates a file object referenced by <code>src</code> which points to the file at the path referenced by <code>band_path</code> (here a GeoTIFF file). The use of the <code>with</code> block as a context manager takes care of closing the connection <code>src</code> when we have finished reading data from the file. The file object <code>src</code> has a <code>read()</code> method which can be used to read data from the file it connects to into our Python program. \n",
    "\n",
    "```{python}\n",
    "src.read(1)\n",
    "```\n",
    "<p></p>\n",
    "\n",
    "For each <code>B*.tif</code> file in a directory, we read it's data into our program as: \n",
    "\n",
    "```{python}\n",
    "# loop over each band, read in the data from the corresponding GeoTIFF file into an ndarray\n",
    "for b in s2_bands:\n",
    "    band_path = os.path.join(image_dir_path, b + \".tif\")\n",
    "    with rasterio.open(band_path) as src:\n",
    "        # append the ndarray storing the Sentinel-2 reflectance data for a band to a list\n",
    "        bands.append(src.read(1))\n",
    "```\n",
    "<p></p>\n",
    "\n",
    "Once we have finished looping over the bands in the directory <code>i</code>, we can stack the <code>ndarray</code> objects in the list <code>bands</code> to form a NumPy <code>ndarray</code> representation of a multiband raster. We do this by passing the list of <code>ndarray</code> objects into the NumPy <code>stack()</code> function.\n",
    "\n",
    "```{python}\n",
    "# empty list to append ndarray of reflectance value for each band to\n",
    "bands = []\n",
    "    \n",
    "# loop over each band, read in the data from the corresponding GeoTIFF file into an ndarray\n",
    "for b in s2_bands:\n",
    "    band_path = os.path.join(image_dir_path, b + \".tif\")\n",
    "    with rasterio.open(band_path) as src:\n",
    "        # append the ndarray storing the Sentinel-2 reflectance data for a band to a list\n",
    "        bands.append(src.read(1))\n",
    "\n",
    "# stack all bands in the list to create a multiband raster\n",
    "multiband_raster = np.stack(bands)\n",
    "```\n",
    "<p></p>\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c94da2-5930-4097-a645-787fd16bea74",
   "metadata": {},
   "source": [
    "Here, we'll keep working the GeoTIFF files in the following directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb59348b-11fe-4dcc-8068-840c49129bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir_path = os.path.join(os.getcwd(), \"week-4\", \"images\", \"ref_agrifieldnet_competition_v1_source_0a664\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8077d761-5404-4ff1-a8e7-6fa2c81a6c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacking bands \n",
    "\n",
    "# Sentinel-2 band names \n",
    "s2_bands = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B09', 'B11', 'B12']\n",
    "\n",
    "# empty list to append ndarray of reflectance value for each band to\n",
    "bands = []\n",
    "    \n",
    "# loop over each band, read in the data from the corresponding GeoTIFF file into an ndarray\n",
    "for b in s2_bands:\n",
    "    print(f\"reading {b}.tif\")\n",
    "    band_path = os.path.join(image_dir_path, b + \".tif\")\n",
    "    with rasterio.open(band_path) as src:\n",
    "        # append the ndarray storing the Sentinel-2 reflectance data for a band to a list\n",
    "        bands.append(src.read(1))\n",
    "\n",
    "# stack all bands in the list to create a multiband raster\n",
    "multiband_raster = np.stack(bands)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6f9a94-606d-4320-bdb8-a4c241e58368",
   "metadata": {},
   "source": [
    "Let's inspect the output of the band stacking workflow. `multiband_raster` should be a `ndarray` objects with rank 3 with three axes (bands, rows, columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb7ad24-3719-4e0b-85d3-cb3e8e984a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"the shape of the bands is {multiband_raster.shape} with rank {len(multiband_raster.shape)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae79be0c-2e52-458b-a66b-1b68df2b7a76",
   "metadata": {},
   "source": [
    "### Map algebra\n",
    "\n",
    "Following <a href=\"https://geocompr.robinlovelace.net/index.html\" target=\"_blank\">Lovelace et al. (2022)</a>, we refer to map algebra as operations that transform raster pixel values via statistical or mathematical operations which can involve combining pixel values from different raster layers or using neighbouring raster values. \n",
    "\n",
    "Local map algebra operations operate on a pixel by pixel basis; the mathematical operation is applied independently to each pixel without reference to neighbouring pixel values. For example, addition, subtraction, multiplication, and logical operations can all be applied on a pixel by pixel basis. \n",
    "\n",
    "A commonly used local operation when working with remote sensing data is computing spectral indices. Spectral indices are pixel by pixel mathematical combinations of spectral reflectance in different wavelengths that are used to monitor vegetation or land surface conditions. Read <a href=\"https://doi.org/10.1038/s43017-022-00298-5\" target=\"_blank\">Zeng et al. (2022)</a> for a review of vegetation indices.\n",
    "\n",
    "The normalised difference vegetation index (NDVI) is used for tracking vegetation condition and representing the greenness of vegetation in a remote sensing image. \n",
    "\n",
    "As we're processing these remote sensing images to generate characteristics of fields that can be used to predict crop type, we will also compute each field's NDVI value as it could contain useful information to discriminate between crop types. \n",
    "\n",
    "The NDVI is computed as:\n",
    "\n",
    "$NDVI=\\frac{NIR-red}{NIR+red}$\n",
    "\n",
    "Thus, the NDVI is computed via division, subtraction, and addition operations computed on a pixel by pixel basis using raster data corresponding to red and near infrared reflectance. \n",
    "\n",
    "NumPy provides tools for fast mathematical operations on `ndarray` objects. If `ndarray` objects have the same shape, a mathematical combination of two or more `ndarray` objects will be computed on an element by element (i.e. pixel by pixel) basis without needing to write for loops to iterate over `ndarray` elements. This feature of NumPy is called *vectorisation* and makes NumPy a useful tool for processing and analysing large amounts of image data.\n",
    "\n",
    "For example, if we wanted to add two NumPy `ndarray` objects together on a pixelwise basis we could do this using for loops in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dffe4bd-203f-4201-8ff1-236dac2ff4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow array addition using for loops\n",
    "a = np.array(\n",
    "    [[1, 2],\n",
    "     [3, 4]])\n",
    "\n",
    "b = np.array(\n",
    "    [[1, 2],\n",
    "     [3, 4]])   \n",
    "\n",
    "result = np.zeros((2, 2))\n",
    "\n",
    "for r in range(0, 2):\n",
    "    print(f\"processing row {r}\")\n",
    "    for c in range(0, 2):\n",
    "        print(f\"processing column {c}\")\n",
    "        \n",
    "        result[r, c] = a[r, c] + b[r, c]\n",
    "\n",
    "print(result)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b4c1e2-e1ce-494d-8f07-218597e43bed",
   "metadata": {},
   "source": [
    "However, this approach will be slow if we are working with large raster datasets in NumPy `ndarray`s. It is also quite verbose, we need to write two for loops just to perform element-wise addition of two arrays. These element-wise operations can be computed in isolation. In other words adding the elements in pixel location `0, 0` does not depend on the result of adding elements in pixel location `0, 1`. This means that element-wise operations can be performed in parallel, which is termed vectorised computation in NumPy, and you can use NumPy's element-wise operations to perform mathematical operations on `ndarray`s in parallel. \n",
    "\n",
    "This has two advantages: speed (particularly when working with large or many images) and cleaner code. The NumPy element-wise approach to adding the `ndarray`s `a` and `b` above is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448de5c2-f6ba-4a38-b6ff-66f616a70b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorised addition using for loops\n",
    "a = np.array(\n",
    "    [[1, 2],\n",
    "     [3, 4]])\n",
    "\n",
    "b = np.array(\n",
    "    [[1, 2],\n",
    "     [3, 4]])  \n",
    "\n",
    "result = a + b\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e65107-2b26-4ace-80d5-42e2fb3b8926",
   "metadata": {},
   "source": [
    "Now we're ready to use NumPy's element wise operations to compute the NDVI. First, let's do this for a single image before extending the routine to automate the generation of NDVI bands for all images. We'll get the first `ndarray` object from `stacked_bands`, a list of rank 3 (bands, rows, cols) `ndarray` objects with each band storing reflectance in different wavelengths. \n",
    "\n",
    "Red reflectance is stored in band 4 of Sentinel-2 images. Thus, red reflectance would be located at index position 3 (the fourth element as we start indexing at 0) on axis 0. \n",
    "\n",
    "Near infrared reflectance is stored in band 8 of Sentinel-2 images. By the same logic near infrared reflectance is located at index position 7 on axis 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac40cf4-18a1-43bc-acbd-0bd59434a4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute NDVI\n",
    "\n",
    "# get the red band - cast to float\n",
    "red = multiband_raster[3, :, :].astype(\"float64\")\n",
    "\n",
    "# get the nir band - cast to float\n",
    "nir = multiband_raster[7, :, :].astype(\"float64\")\n",
    "\n",
    "# compute the ndvi\n",
    "ndvi = (nir-red)/(nir+red)\n",
    "\n",
    "print(f\"the shape of the ndvi image is {ndvi.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f194fca7-aee3-43a3-9738-9ff18e2792f2",
   "metadata": {},
   "source": [
    "NDVI values fall between -1 and 1 with values closer to 1 indicating greener vegetation and values less than 0 indicating an absence of vegetation. Let's visualise the NDVI band and check the values fall within this range. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d265893a-7e3d-4d77-9c81-800b8bdbdd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise the ndvi image\n",
    "px.imshow(ndvi, color_continuous_scale=\"viridis\", contrast_rescaling=\"minmax\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0acc22a-3674-40b3-a2c7-885601926b28",
   "metadata": {},
   "source": [
    "You will have noticed that prior to computing the NDVI values we converted the red and near infrared `ndarray` objects to `float64` type. This is because NDVI values represent variation in vegetation conditions using numbers with digits before and after the decimal point (a NDVI value of 0.8 would indicate green vegetation and a NDVI value of -0.2 would indicate an absence of green vegetation and possibly water cover). Thus, it is more appropriate to use floating point numbers to store NDVI values.\n",
    "\n",
    "If you check the data type (`dtype`) of the values of the multiband `ndarray` objects storing reflectance data you will see that they are of type `uint8`. This means they are unsigned integers - they cannot represent negative values. However, NDVI values can be negative. Therefore, we should convert these values to a data type that can store negative and positive (i.e. signed) numbers. \n",
    "\n",
    "We use the NumPy method `astype()` to cast an `ndarray` to a new `dtype`. You can read more about NumPy data types <a href=\"https://wesmckinney.com/book/numpy-basics.html#numpy_dtypes\" target=\"_blank\">here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5ec2e7-1f2c-44e0-a194-4fd99db5544c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The dtype of the red band is {multiband_raster[3, :, :].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed3bf9c-1aa9-4461-add7-1c5a03e0712c",
   "metadata": {},
   "source": [
    "Now we have demonstrated how to compute NDVI values from NumPy `ndarray` objects, we can edit our existing routine that created rank 3 `ndarray` objects stacking by raster layers to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10695be9-146c-4816-9cd8-29b1c3e3accb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacking bands \n",
    "\n",
    "# Sentinel-2 band names \n",
    "s2_bands = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B09', 'B11', 'B12']\n",
    "\n",
    "# empty list to append ndarray of reflectance value for each band to\n",
    "bands = []\n",
    "    \n",
    "# loop over each band, read in the data from the corresponding GeoTIFF file into an ndarray\n",
    "for b in s2_bands:\n",
    "    print(f\"reading {b}.tif\")\n",
    "    band_path = os.path.join(image_dir_path, b + \".tif\")\n",
    "    with rasterio.open(band_path) as src:\n",
    "        # append the ndarray storing the Sentinel-2 reflectance data for a band to a list\n",
    "        bands.append(src.read(1))\n",
    "\n",
    "# stack all bands in the list to create a multiband raster\n",
    "multiband_raster = np.stack(bands)\n",
    "    \n",
    "# make NDVI band\n",
    "red = multiband_raster[3,:,:].astype(\"float64\")\n",
    "nir = multiband_raster[7,:,:].astype(\"float64\")\n",
    "ndvi = (nir-red)/(nir+red)\n",
    "ndvi = np.expand_dims(ndvi, axis=0) # add a bands axis\n",
    "multiband_raster = np.concatenate((multiband_raster, ndvi), axis=0) # stack the ndvi band"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec668557-9925-4356-ba14-d8fdf3e949e8",
   "metadata": {},
   "source": [
    "Let's visualise the NDVI band in `multiband_raster` to check it looks sensible. Also, note how we can use the index value `-1` for the last element along an axis. The NDVI band was stacked at the end of the 0 axis of the `ndarray` so the NDVI raster is the last slice of the `ndarray` on the 0 axis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2024564c-20e8-4c91-b0b9-56c1a26dec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"the shape of the first ndarray in stacked_bands is {multiband_raster.shape}\")\n",
    "print(f\"the data type of the ndarray is {multiband_raster.dtype}\")\n",
    "\n",
    "ndvi = multiband_raster[-1, :,  :]\n",
    "\n",
    "# visualise the ndvi image\n",
    "px.imshow(ndvi, color_continuous_scale=\"viridis\", contrast_rescaling=\"minmax\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f10285-c7b1-4bb3-9176-4670fa1a37b5",
   "metadata": {},
   "source": [
    "### Labels and field id bands\n",
    "\n",
    "So, far we have built a routine that processes the Sentinel-2 images using operations applied to raster data. These will form our predictor variables (features) that can be used to train a machine learning model that classifies crop type in subsequent tasks. Now we need to get the crop type labels that our model will learn to predict (classify) from the Sentinel-2 remote sensing data. \n",
    "\n",
    "We can extend our program to do this. After we generate and stack the NDVI band we can read in the field id and crop type labels data and append them to the `ndarray` object too. \n",
    "\n",
    "Look for the following code in the routine below to see how this is done: \n",
    "\n",
    "```python\n",
    "### HERE WE ARE STACKING THE FIELD ID BAND \n",
    "field_id_path = os.path.join(image_dir_path, \"field/field_ids.tif\")\n",
    "with rasterio.open(field_id_path) as src:\n",
    "    field_ids = src.read().astype(\"float64\")\n",
    "    field_ids[field_ids == 0] = np.nan\n",
    "    multiband_raster = np.concatenate((bands, field_ids), axis=0)\n",
    "```\n",
    "\n",
    "A few things to note:\n",
    "\n",
    "* the GeoTIFF files storing the field ids (`field_ids.tif`) and crop type labels (`raster_labels.tif`) are stored in sub-directories within each directory. This means we need to create a path that points to these files within their sub-directories.\n",
    "* pixels in the `field_ids.tif` raster with a value of 0 do not correspond to crop type labels. These pixels are not of interest to us here so we can set them to `np.nan`. Later we will drop all `np.nan` values so our dataset only reflects locations with crop type labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bd2e99-e950-4fb3-a8d6-c689377d646d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacking bands \n",
    "\n",
    "# Sentinel-2 band names \n",
    "s2_bands = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B09', 'B11', 'B12']\n",
    "\n",
    "# empty list to append ndarray of reflectance value for each band to\n",
    "bands = []\n",
    "    \n",
    "# loop over each band, read in the data from the corresponding GeoTIFF file into an ndarray\n",
    "for b in s2_bands:\n",
    "    print(f\"reading {b}.tif\")\n",
    "    band_path = os.path.join(image_dir_path, b + \".tif\")\n",
    "    with rasterio.open(band_path) as src:\n",
    "        # append the ndarray storing the Sentinel-2 reflectance data for a band to a list\n",
    "        bands.append(src.read(1))\n",
    "\n",
    "# stack all bands in the list to create a multiband raster\n",
    "multiband_raster = np.stack(bands)\n",
    "    \n",
    "# make NDVI band\n",
    "red = multiband_raster[3,:,:].astype(\"float64\")\n",
    "nir = multiband_raster[7,:,:].astype(\"float64\")\n",
    "ndvi = (nir-red)/(nir+red)\n",
    "ndvi = np.expand_dims(ndvi, axis=0) # add a bands axis\n",
    "multiband_raster = np.concatenate((multiband_raster, ndvi), axis=0) # stack the ndvi band\n",
    "    \n",
    "### HERE WE ARE STACKING THE FIELD ID BAND \n",
    "field_id_path = os.path.join(image_dir_path, \"field/field_ids.tif\")\n",
    "with rasterio.open(field_id_path) as src:\n",
    "    field_ids = src.read().astype(\"float64\")\n",
    "    field_ids[field_ids == 0] = np.nan\n",
    "    multiband_raster = np.concatenate((bands, field_ids), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e899715-45bf-4783-9371-e9d51115c277",
   "metadata": {},
   "source": [
    "#### Recap quiz\n",
    "\n",
    "**Can you extend the above routine to read in crop type labels associated with each 256 x 256 pixel image footprint and append this data to the `ndarray` object `bands`. You should follow a similar logic that was used for reading and appending the field id band above. There is a sub-directory `label` which stores a GeoTIFF file of crop type labels `raster_labels.tif`. Edit the code snippet below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af307ea-6b33-4346-ab7f-da007387f378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacking bands \n",
    "\n",
    "# Sentinel-2 band names \n",
    "s2_bands = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B09', 'B11', 'B12']\n",
    "\n",
    "# empty list to append ndarray of reflectance value for each band to\n",
    "bands = []\n",
    "    \n",
    "# loop over each band, read in the data from the corresponding GeoTIFF file into an ndarray\n",
    "for b in s2_bands:\n",
    "    print(f\"reading {b}.tif\")\n",
    "    band_path = os.path.join(image_dir_path, b + \".tif\")\n",
    "    with rasterio.open(band_path) as src:\n",
    "        # append the ndarray storing the Sentinel-2 reflectance data for a band to a list\n",
    "        bands.append(src.read(1))\n",
    "\n",
    "# stack all bands in the list to create a multiband raster\n",
    "multiband_raster = np.stack(bands)\n",
    "    \n",
    "# make NDVI band\n",
    "red = multiband_raster[3,:,:].astype(\"float64\")\n",
    "nir = multiband_raster[7,:,:].astype(\"float64\")\n",
    "ndvi = (nir-red)/(nir+red)\n",
    "ndvi = np.expand_dims(ndvi, axis=0) # add a bands axis\n",
    "multiband_raster = np.concatenate((multiband_raster, ndvi), axis=0) # stack the ndvi band\n",
    "    \n",
    "### HERE WE ARE STACKING THE FIELD ID BAND \n",
    "field_id_path = os.path.join(image_dir_path, \"field/field_ids.tif\")\n",
    "with rasterio.open(field_id_path) as src:\n",
    "    field_ids = src.read().astype(\"float64\")\n",
    "    field_ids[field_ids == 0] = np.nan\n",
    "    multiband_raster = np.concatenate((multiband_raster, field_ids), axis=0)\n",
    "    \n",
    "## HERE WE ARE STACKING THE CROP TYPE LABELS BAND \n",
    "\n",
    "## ADD CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103b72b1-a4e8-45ec-a704-10514e30047a",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>answer</b></summary>\n",
    "\n",
    "```{python}\n",
    "# stacking bands \n",
    "\n",
    "# Sentinel-2 band names \n",
    "s2_bands = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B09', 'B11', 'B12']\n",
    "\n",
    "# empty list to append ndarray of reflectance value for each band to\n",
    "bands = []\n",
    "    \n",
    "# loop over each band, read in the data from the corresponding GeoTIFF file into an ndarray\n",
    "for b in s2_bands:\n",
    "    print(f\"reading {b}.tif\")\n",
    "    band_path = os.path.join(image_dir_path, b + \".tif\")\n",
    "    with rasterio.open(band_path) as src:\n",
    "        # append the ndarray storing the Sentinel-2 reflectance data for a band to a list\n",
    "        bands.append(src.read(1))\n",
    "\n",
    "# stack all bands in the list to create a multiband raster\n",
    "multiband_raster = np.stack(bands)\n",
    "    \n",
    "# make NDVI band\n",
    "red = multiband_raster[3,:,:].astype(\"float64\")\n",
    "nir = multiband_raster[7,:,:].astype(\"float64\")\n",
    "ndvi = (nir-red)/(nir+red)\n",
    "ndvi = np.expand_dims(ndvi, axis=0) # add a bands axis\n",
    "multiband_raster = np.concatenate((multiband_raster, ndvi), axis=0) # stack the ndvi band\n",
    "    \n",
    "### HERE WE ARE STACKING THE FIELD ID BAND \n",
    "field_id_path = os.path.join(image_dir_path, \"field/field_ids.tif\")\n",
    "with rasterio.open(field_id_path) as src:\n",
    "    field_ids = src.read().astype(\"float64\")\n",
    "    field_ids[field_ids == 0] = np.nan\n",
    "    multiband_raster = np.concatenate((multiband_raster, field_ids), axis=0)\n",
    "    \n",
    "## HERE WE ARE STACKING THE CROP TYPE LABELS BAND \n",
    "labels_path = os.path.join(image_dir_path, \"label/raster_labels.tif\")\n",
    "with rasterio.open(labels_path) as src:\n",
    "    multiband_raster = np.concatenate((multiband_raster, src.read()), axis=0)\n",
    "\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f599e20a-f227-40be-b01f-853bd979aecd",
   "metadata": {},
   "source": [
    "### Reshaping raster data\n",
    "\n",
    "For each 256 x 256 pixel Sentinel-2 image footprint, we have have created a multiband raster with each band storing reflectance in different wavelengths, computed an NDVI band and appended that to the stack of raster bands, and also stacked bands representing crop type labels for each pixel and a field id indicating which field a pixel belongs to. We have an `ndarray` object of rank 3 with axis 0 for bands, axis 1 for rows, and axis 2 for columns.  \n",
    "\n",
    "Our goal is to create a tabular dataset where each column represents a variable (e.g. crop type, spectral reflectance, or field id) and each row represents a field. This tabular format is what is required for many machine learning tasks. \n",
    "\n",
    "The next stage in our data transformation routine is to reshape the data from an image-style structure (i.e. where variables are stored along the bands or 0 axis) to a tabular style format where variables are stored along the columns axis. A tabular style dataset can be represented as a rank 2 `ndarray` (axis 0 for rows and axis 1 for columns). Therefore, we need a reshaping operation that will transform a rank 3 `ndarray` object to a rank 2 `ndarray` object and arrange variables along the 1 axis.\n",
    "\n",
    "![](https://github.com/data-analysis-3300-3003/figs/raw/main/week-4-reshaping.jpg)\n",
    "\n",
    "An `ndarray` object has a <a href=\"https://numpy.org/doc/stable/reference/generated/numpy.reshape.html\" target=\"_blank\">`reshape()`</a> method. This method takes in a tuple of integers that describe the shape of the new `ndarray`. For example, let's demonstrate reshaping a `3 x 3` `ndarray` to a `9 x 1` `ndarray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e07b13-047b-4cfc-b1c3-184a7e8c79b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 2, 3], \n",
    "             [1, 2, 3],\n",
    "             [1, 2, 3]])\n",
    "\n",
    "a_reshaped = a.reshape((9, 1))\n",
    "print(a_reshaped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70462985-b7c2-442e-b48c-6f5509542a07",
   "metadata": {},
   "source": [
    "The transpose is another common operation used for reshaping array-like objects. The transpose operation flips the rows and columns of an array. The transpose of a `5 x 4` array is a `4 x 5` array. NumPy `ndarray` objects have a transpose property `T` which returns the transpose of the array. We can demonstrate a few examples of viewing the transpose of an `ndarray` so you can build up an intuition of how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b3aa90-87cd-4a1e-b35e-adbd47a1d82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 2, 3, 4], \n",
    "             [1, 2, 3, 4],\n",
    "             [1, 2, 3, 4]])\n",
    "\n",
    "a_transposed = a.T\n",
    "print(\"Note how the 1 valued elements are now aligned along the columns or 1 axis\")\n",
    "print(a_transposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a96d682-88a5-41e5-a958-3ca310111156",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([[3, 3, 3], \n",
    "             [4, 4, 4],\n",
    "             [5, 5, 5]])\n",
    "\n",
    "b_transposed = b.T\n",
    "print(\"Note how the 3 valued elements are now aligned along the rows or 0 axis\")\n",
    "print(b_transposed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca901a3-ae40-4000-ac0f-64b6b9f46ad9",
   "metadata": {},
   "source": [
    "We'll need to reshape the `ndarray` object from rank 3 with shape `(bands, rows, cols)`  to a rank 2 array with shape  `(bands, (rows * cols))`. Instead of arranging the elements for each variable (i.e. reflectance values in different wavelengths, crop type, field id) in an image-style format (like a rank 2 array), the reshape operation will transform the `ndarray` so bands remain on the 0-axis but become rows and the the data values will be arranged along the 1 axis (columns). \n",
    "\n",
    "Let's demonstrate this with the the `ndarray` in `multiband_raster`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6f875c-b214-4458-8e9d-358f1e1db6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"the shape of multiband raster is {multiband_raster.shape}\")\n",
    "\n",
    "rows = multiband_raster.shape[1]\n",
    "cols = multiband_raster.shape[2]\n",
    "n_bands = multiband_raster.shape[0]\n",
    "multiband_reshaped = multiband_raster.reshape(n_bands, rows*cols)\n",
    "print(f\"the shape of the reshaped raster is {multiband_reshaped.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e29a6c-4e1d-41f1-863e-1e2adca04ab4",
   "metadata": {},
   "source": [
    "Now the we have reshaped the multiband raster to a tabular format, but the variables are arranged down the 0 axis (rows) and we want them arranged as columns. We can use a transpose operation to flip our now reshaped rank 2 `ndarray` to the desired tabular format structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f1e8d7-5bcf-48b4-9f81-7737473d76b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_array = multiband_reshaped.reshape(n_bands, rows*cols).T\n",
    "print(f\"the shape of the transposed array is {tabular_array.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53715505-3954-4dbe-a030-19f12619ea07",
   "metadata": {},
   "source": [
    "Now we know how to transform our rank 3 `ndarray` objects representing multiband rasters to an `ndarray` representing a tabular format, we can extend our routine to perform the reshaping operations after the band stacking operations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efc0402-558e-4965-a09e-71378f133b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacking bands \n",
    "\n",
    "# Sentinel-2 band names \n",
    "s2_bands = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B09', 'B11', 'B12']\n",
    "\n",
    "# empty list to append ndarray of reflectance value for each band to\n",
    "bands = []\n",
    "    \n",
    "# loop over each band, read in the data from the corresponding GeoTIFF file into an ndarray\n",
    "for b in s2_bands:\n",
    "    print(f\"reading {b}.tif\")\n",
    "    band_path = os.path.join(image_dir_path, b + \".tif\")\n",
    "    with rasterio.open(band_path) as src:\n",
    "        # append the ndarray storing the Sentinel-2 reflectance data for a band to a list\n",
    "        bands.append(src.read(1))\n",
    "\n",
    "# stack all bands in the list to create a multiband raster\n",
    "multiband_raster = np.stack(bands)\n",
    "    \n",
    "# make NDVI band\n",
    "red = multiband_raster[3,:,:].astype(\"float64\")\n",
    "nir = multiband_raster[7,:,:].astype(\"float64\")\n",
    "ndvi = (nir-red)/(nir+red)\n",
    "ndvi = np.expand_dims(ndvi, axis=0) # add a bands axis\n",
    "multiband_raster = np.concatenate((multiband_raster, ndvi), axis=0) # stack the ndvi band\n",
    "    \n",
    "### HERE WE ARE STACKING THE FIELD ID BAND \n",
    "field_id_path = os.path.join(image_dir_path, \"field/field_ids.tif\")\n",
    "with rasterio.open(field_id_path) as src:\n",
    "    field_ids = src.read().astype(\"float64\")\n",
    "    field_ids[field_ids == 0] = np.nan\n",
    "    multiband_raster = np.concatenate((multiband_raster, field_ids), axis=0)\n",
    "    \n",
    "## HERE WE ARE STACKING THE CROP TYPE LABELS BAND \n",
    "labels_path = os.path.join(image_dir_path, \"label/raster_labels.tif\")\n",
    "with rasterio.open(labels_path) as src:\n",
    "    multiband_raster = np.concatenate((multiband_raster, src.read()), axis=0)\n",
    "\n",
    "# reshape multiband raster to tabular format\n",
    "rows = multiband_raster.shape[1]\n",
    "cols = multiband_raster.shape[2]\n",
    "n_bands = multiband_raster.shape[0]\n",
    "reshaped = multiband_raster.reshape(n_bands, rows*cols)\n",
    "tabular = reshaped.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd34d40e-a6e5-4c50-8265-40d7444902dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"the shape of the ndarray representing the data in a tabular format is {tabular.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
