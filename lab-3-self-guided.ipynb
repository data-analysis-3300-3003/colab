{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63254a69-9c6a-4510-a551-3a9060d437a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "\n",
    "## Exploratory data analysis\n",
    "\n",
    "Exploratory data analysis is an activity where you ....... *explore your data*. It's often conducted towards the beginning of a data science or analysis workflow and is an interactive process to build up your familiarity with the data; identify its structure and patterns; spot noise, errors, and missing values; and begin to formulate research questions and hypotheses.  \n",
    "\n",
    "Chapter 7 of R for Data Science <a href=\"https://r4ds.had.co.nz/exploratory-data-analysis.html\" target=\"_blank\">(Wickham and Grolemund, 2017)</a> provides an excellant overview of techniques for exploratory data analysis. They suggest that two questions should guide your initial exploration of datasets:\n",
    "\n",
    "* What type of variation occurs within variables?\n",
    "* What type of covariation occurs between variables?\n",
    "\n",
    "A variable is a property or feature of interest that can be measured and a value is the state of the variable when it was measured. Columns in a `DataFrame` or `GeoDataFrame` or bands in raster often correspond to variables and cells in a table or pixels in a raster correspond to values for an observation. \n",
    "\n",
    "### Task\n",
    "\n",
    "Here, you will build on the data visualisation skills from the previous lab to explore crop yield data collected by a harvester in Western Australia. You will use data visualisations and summaries to identify noise or errors in the dataset and remove or clean them. In this lab you will learn to:\n",
    "\n",
    "* generate summary tables and descriptive statistics\n",
    "* visualise data distributions\n",
    "* visualise relationships between variables\n",
    "* identify and remove missing or noisy values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96244668-11dd-467a-b73d-e95c774a4781",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Run the labs\n",
    "\n",
    "You can run the labs locally on your machine or you can use cloud environments provided by Google Colab. **If you're working with Google Colab be aware that your sessions are temporary and you'll need to take care to save, backup, and download your work.**\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/data-analysis-3300-3003/colab/blob/main/lab-3-self-guided.ipynb\" target=\"_blank\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "### Download data\n",
    "\n",
    "If you need to download the data for this lab, run the following code snippet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0721da-91c0-485f-8c76-1fe26cc91e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if \"week-3\" not in os.listdir(os.getcwd()):\n",
    "    os.system('wget \"https://github.com/data-analysis-3300-3003/data/raw/main/data/week-3.zip\"')\n",
    "    os.system('unzip \"week-3.zip\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a9f398-37ef-42cf-a344-aee4f8eabde4",
   "metadata": {},
   "source": [
    "### Working in Colab\n",
    "\n",
    "If you're working in Google Colab, you'll need to install the required packages that don't come with the colab environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be90d5ea-91bc-4fe9-a396-00d4e4e10711",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    !pip install geopandas\n",
    "    !pip install pyarrow\n",
    "    !pip install mapclassify\n",
    "    !pip install rasterio\n",
    "    !pip install libpysal\n",
    "    !pip install esda\n",
    "    !pip install splot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a91b416-8469-4a0c-938a-160ea1cdfe2c",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a992cb-a166-441d-a313-4e218396a4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "import plotly.io as pio\n",
    "import esda\n",
    "\n",
    "from splot.esda import plot_moran\n",
    "from libpysal.weights import KNN, lag_spatial\n",
    "\n",
    "# setup renderer\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    pio.renderers.default = \"colab\"\n",
    "else:\n",
    "    pio.renderers.default = \"jupyterlab\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803b0f5b-16d6-4874-8c7d-eb5b6bad9fe5",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb674bae-07ca-420e-b6c1-7109cf092fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the crop yield data\n",
    "crop_yield_data_path = os.path.join(os.getcwd(), \"week-3\")\n",
    "\n",
    "# Get a list of crop yield data\n",
    "crop_yield_data_files = os.listdir(crop_yield_data_path)\n",
    "\n",
    "# Combine the geojson files into one GeoDataFrame\n",
    "dfs = []\n",
    "\n",
    "for i in crop_yield_data_files:\n",
    "    if i.endswith(\".geojson\"):\n",
    "        print(f\"Loading file {i} into a Geopandas GeoDataFrame\")\n",
    "        tmp_df = gpd.read_file(os.path.join(crop_yield_data_path, i))\n",
    "        dfs.append(tmp_df)\n",
    "\n",
    "gdf = pd.concat(dfs, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2de0116-5d5f-4e58-ad18-ad9063f1512b",
   "metadata": {},
   "source": [
    "## Data summaries\n",
    "\n",
    "An initial data exploration task is to produce summary statistics for the variables in our datasets. Pandas `DataFrame`s and GeoPandas `GeoDataFrame`s have a `describe()` method which generates a `DataFrame` of summary statistics for each variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66aecec-9ae1-458a-91b1-697199352fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe our DataFrame of crop yield data\n",
    "gdf.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c8c036-a285-4d95-9ff2-6d95cc86c5a0",
   "metadata": {},
   "source": [
    "`describe()` returns to us a count of the number of observations in a variable, the mean value for observations in a variable, and summary statistics describing the distribution and range of values (standard deviation, percentiles (median = 50th percentile), and min and max values).\n",
    "\n",
    "However, there are two main groups in our dataset: canola observations and wheat observations denoted by the `Variety` column. It will be more informative to generate summary statistcs for each group separately. We can do this using the Pandas `groupby()` function which splits a `DataFrame` into subsets based upon a grouping variable, computes statistics for each subset, and then combines the results. Here, we need to `groupby()` `Variety` to generate summary statistics for each crop type. \n",
    "\n",
    "We'll also generate these summary statistics within a context manager (denoted by a `with` block). This context allows us to change the default display values for a `DataFrame` only for this context without affecting the global defaults that apply to the rest of the notebook. This is a useful trick in case you have a particular need to control how a `DataFrame` is displayed (e.g. printing all rows as specified by the `display.max_rows` option)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8907c60d-4f8f-4407-a132-d6404f446bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_rows\", None, \"display.float_format\", lambda x: \"%.3f\" % x):\n",
    "    display(gdf.groupby([\"Variety\"]).describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f52aa7-b6a8-4a22-aac8-3d297ce9a610",
   "metadata": {},
   "source": [
    "This still isn't a very helpful layout to view the summary statistics as not all of the statistics can be displayed. Let's transpose the summary statistics so rows become columns and vice versa using the `T` transpose operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c859a2-5d02-4c1f-8514-694838b98488",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_rows\", None, \"display.float_format\", lambda x: \"%.3f\" % x):\n",
    "    display(gdf.loc[:, [\"Variety\", \"DryYield\", \"gndvi\", \"ndyi\"]].groupby([\"Variety\"]).describe().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc6e979-8c49-41c8-bbad-7813c0b22391",
   "metadata": {},
   "source": [
    "## Data distributions\n",
    "\n",
    "The mean tells us the average value for a variable. However, it is susceptible to outliers and extreme values. Therefore, it is important to view the mean and the median (50th percentile) together as the median is not affected by extreme values. \n",
    "\n",
    "However, neither the mean or the median reveal the spread or distribution of values for a variable. The min and max values tell us what the range of values are for a variable. This can be useful for detecting potential measurement error and noise (e.g. is the max value for wheat yield sensible?).\n",
    "\n",
    "The inter-quartile range (difference between the 75th and 25th percentile values) tells us how spread out the data is around the median and the standard deviation tells us how spread out the data is around the mean. Assuming a normal distribution, ~68% of the values are within one standard deviation of the mean. \n",
    "\n",
    "It is often useful to visualise the distribution of variables. A histogram is a common visualisation for distributions. The height of the bars of a histogram correspond to the count of values that fall within the bin. The width of the bar corresponds to the bin width. \n",
    "\n",
    "#### Recap quiz\n",
    "\n",
    "<details>\n",
    "    <summary><b>What is a limitation of using min and max values to represent the distribition of values for a variable?</b></summary>\n",
    "The min and max values can be affected by extreme values and don't tell us anything about the shape or density of the distribution of data values.\n",
    "</details>\n",
    "\n",
    "<p></p>\n",
    "\n",
    "<details>\n",
    "    <summary><b>If the standard deviation is small relative to the mean, what does this tell us about the spread of the data?</b></summary>\n",
    "There is not much spread in the data away from the mean.\n",
    "</details>\n",
    "\n",
    "<p></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b92b3c3-5505-4bb2-b319-53d38a93332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(\n",
    "    data_frame=gdf, \n",
    "    x=\"DryYield\", \n",
    "    facet_col=\"Variety\", \n",
    "    hover_data=[\"DryYield\", \"Elevation\", \"WetMass\"])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde9374d-2deb-4af9-9a21-b17714c97080",
   "metadata": {},
   "source": [
    "The `histogram()` function from Plotly Express has a `nbins` parameter that can be used to specify the number of bins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a7535d-7098-42c9-a168-a722c6cdded9",
   "metadata": {},
   "source": [
    "#### Recap quiz\n",
    "\n",
    "**Use the Plotly Express `nbins` parameter of the `histogram()` function to change the number bins, and consequently the bin width, and explore how this affects the visualisation of the distribution.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64824f8d-58b9-4dbd-8b8a-85940d0d34a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add code here ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be1554c-1d5c-4a21-a9b3-7ed862799bd3",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>answer</b></summary>\n",
    "    \n",
    "```{python}\n",
    "fig = px.histogram(\n",
    "    data_frame=gdf, \n",
    "    x=\"DryYield\", \n",
    "    facet_col=\"Variety\", \n",
    "    nbins=5, ### CHANGE THIS VALUE\n",
    "    hover_data=[\"DryYield\", \"Elevation\", \"WetMass\"])\n",
    "fig.show()\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098918e3-c843-45f5-af7b-cc2944a68129",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>What happens if you generate a histogram with too large a bin width?</b></summary>\n",
    "You will smooth out variation in the data and will not accurately reflect the shape of the distribution of the data.\n",
    "</details>\n",
    "\n",
    "<p></p>\n",
    "\n",
    "<details>\n",
    "    <summary><b>What happens if you generate a histogram with too small a bin width?</b></summary>\n",
    "You might not be able to see the dominant shape of the distribution of data values as the histogram could appear \"spikey\" with local variability in the distribution of values emphasised.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e752d7f-9325-4561-8d80-72979d8e2b9b",
   "metadata": {},
   "source": [
    "## Subsetting pandas `DataFrame`s\n",
    "\n",
    "To subset data from a pandas `DataFrame` we use the square brackets `[]` to specify the data values we'd like to extract. The `[]` operator can be thought of as a get item operation. \n",
    "\n",
    "**Selection by labels**\n",
    "\n",
    "*Selection by labels* refers to selecting values from a `DataFrame` by their label (i.e. column name).\n",
    "\n",
    "* To select a column from a `DataFrame` we pass the column name into `[]` (e.g. `dry_yield = gdf[\"DryYield\"]` where `dry_yield` is a `Series` object).\n",
    "* To select many columns from a `DataFrame` we pass a list of column names into `[]` (e.g. (e.g. `df_yield = gdf[[\"DryYield\", \"Variety\"]]` where `df_yield` is a `DataFrame` object).\n",
    "\n",
    "**Selection by position**\n",
    "\n",
    "*Selection by position* refers to selecting values from a `DataFrame` by their index position (i.e. row or column number starting at 0).\n",
    "\n",
    "* To select the $n^{th}$ row pass in `[n-1:n]`. Remember that Python indexes from zero so the $n-1$ index position is the $n^{th}$ row. The slice operator `:` is exclusive so `[n-1:n]` will only select the row at `n-1` (e.g. to select the $2^{nd}$ row use `df_row_2 = gdf[1:2]`).\n",
    "* To select a slice of rows use the slice operator (e.g. to select the first 10 rows use `df_10_rows = gdf[0:10]`).\n",
    "\n",
    "**Selection by condition**\n",
    "\n",
    "*Selection by condition* selects rows that are `True` based on a condition (e.g. selecting all rows with a `DryYield` greater than 1.5 - `df_yield_gt_1_5 = gdf[gdf[\"DryYield\"] > 1.5]`).\n",
    "\n",
    "**`loc[]` and `iloc[]`**\n",
    "\n",
    "The more robust approach to subsetting data from `DataFrame`s is using the `loc` and `iloc` methods, which also support multi-index selection (i.e. selecting rows and columns). \n",
    "\n",
    "* `loc` is used for selecting by labels (e.g. `df_yield = gdf.loc[:, [\"DryYield\", \"Variety\"]]` - note the `[:, [\"DryYield\", \"Variety\"]]` syntax where `:` means select all rows).\n",
    "* `iloc` is used for selecting by position (e.g. to select the first 10 rows use `df_10_rows = gdf.iloc[0:10, :]`).\n",
    "* To select the first 10 rows and columns we'd use `df_10_rows_10_cols = gdf.iloc[0:10, 0:10]`).\n",
    "\n",
    "#### Recap quiz\n",
    "\n",
    "<details>\n",
    "    <summary><b>How many rows will the object referenced by <code>df_temp</code> have after calling <code>df_temp=df.iloc[0:5, :]</code>?</b></summary>\n",
    "5 rows at index positions 0 to 4 from the <code>DataFrame</code> <code>df</code>.\n",
    "</details>\n",
    "\n",
    "<p></p>\n",
    "\n",
    "<details>\n",
    "    <summary><b>How many columns from <code>df</code> will the object referenced by <code>df_temp</code> have after calling <code>df_temp=df.iloc[0:5, :]</code>?</b></summary>\n",
    "All the columns from <code>df</code>.\n",
    "</details>\n",
    "\n",
    "<p></p>\n",
    "\n",
    "**Use `loc` and the `DataFrame` referenced by `gdf` to select all rows where `DryYield` is greater than 2.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af762c12-4a99-4389-9c49-fd6176220aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ADD CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13f16a0-b590-4d79-a33f-7d17894291fc",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>answer</b></summary>\n",
    "\n",
    "```{python}\n",
    "df_gt_2 = gdf.loc[(gdf[\"DryYield\"] > 2), :]\n",
    "df_gt_2.head()\n",
    "```\n",
    "</details>\n",
    "\n",
    "<p></p>\n",
    "\n",
    "These are some useful resources on subsetting pandas `DataFrame`s:\n",
    "\n",
    "* pandas Getting Started: <a href=\"https://pandas.pydata.org/docs/getting_started/intro_tutorials/03_subset_data.html#how-do-i-select-specific-rows-and-columns-from-a-dataframe\" target=\"_blank\">How do I select specific rows and columns from a DataFrame?</a>\n",
    "* The first few sections of the pandas docs on <a href=\"https://pandas.pydata.org/docs/user_guide/indexing.html#selection-by-position\" target=\"_blank\">Indexing and selecting data</a>\n",
    "* McKinney (2022) Python for Data Analysis - section on <a href=\"https://pandas.pydata.org/docs/user_guide/indexing.html#selection-by-position\" target=\"_blank\">Indexing, selection, and filtering</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085e8ed0-6b7a-470c-a46f-797835952c29",
   "metadata": {},
   "source": [
    "## Outliers\n",
    "\n",
    "The majority of data values on the histograms above are concentrated on the far left of the figure. If you zoom in you will see there are a few isolated extreme or outlier yield values, which are masking the dominant pattern of the distribution. Detecting outliers is an important part of exploratory data analysis. \n",
    "\n",
    "Now that outliers have been detected we need to fix or remove them. A common way to detect outliers is to use a threshold based on percentile or standard deviation values. Here, we'll say an outlier is any value that is more or less than three standard deviations from the mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f881c92a-2e70-4d4c-aa36-84bb3090d2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canola\n",
    "df_canola = gdf.loc[gdf[\"Variety\"] == \"43Y23 RR\", :]\n",
    "print(f\"There are {df_canola.shape[0]} canola rows BEFORE dropping outliers\")\n",
    "df_canola = df_canola.loc[(df_canola[\"DryYield\"]-df_canola[\"DryYield\"].mean()).abs() < (3*df_canola[\"DryYield\"].std()), :]\n",
    "print(f\"There are {df_canola.shape[0]} canola rows AFTER dropping outliers\")\n",
    "\n",
    "# Wheat\n",
    "df_wheat = gdf.loc[gdf[\"Variety\"] == \"Ninja\", :]\n",
    "print(f\"There are {df_wheat.shape[0]} wheat rows BEFORE dropping outliers\")\n",
    "df_wheat = df_wheat.loc[(df_wheat[\"DryYield\"]-df_wheat[\"DryYield\"].mean()).abs() < (3*df_wheat[\"DryYield\"].std()), :]\n",
    "print(f\"There are {df_wheat.shape[0]} wheat rows AFTER dropping outliers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108a33e9-5781-4863-a5de-db97fc53619b",
   "metadata": {},
   "source": [
    "#### Recap quiz\n",
    "\n",
    "<details>\n",
    "    <summary><b>Is <code>df_canola = gdf.loc[gdf[\"Variety\"] == \"43Y23 RR\", :]</code> an example of <em>selection by condition</em> or <em>selection by position</em>?</b></summary>\n",
    "Selection by condition. Here, we're using a logical condition that evaluates to <code>True</code> for all rows where the value in the <code>Variety</code> column is <code>43Y23 RR</code>.\n",
    "</details>\n",
    "\n",
    "<p></p>\n",
    "\n",
    "<details>\n",
    "    <summary><b>What is the <code>abs()</code> function being used for in the conditional selection of rows whose <code>DryYield</code> value is more / less than three standard deviations from the mean?</b></summary>\n",
    "<code>abs()</code> returns the absolute numeric value (so -2 would be returned as 2). This converts all negative deviations from the mean to positive and allows us to test for rows less than 3 standard deviations from the mean and select all rows within three standard deviations of the mean. \n",
    "</details>\n",
    "\n",
    "<p></p>\n",
    "\n",
    "<details>\n",
    "    <summary><b>What is the <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.concat.html\" target=\"_blank\">pandas <code>concat()</code></a> function used for?</b></summary>\n",
    "    To combine (concatenate) <code>DataFrames</code> along an axis. Here, we specify the 0 axis which refers to rows to stack two `DataFrame`s on top of each other.  \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f01df53-89e0-462a-9ecf-336ec00551c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine filtered dfs\n",
    "gdf_clean = pd.concat([df_canola, df_wheat], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b6158e-05e4-4a07-bdd2-ce46832409e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(\n",
    "    data_frame=gdf_clean, \n",
    "    x=\"DryYield\", \n",
    "    facet_col=\"Variety\", \n",
    "    marginal=\"box\", \n",
    "    hover_data=[\"DryYield\", \"Elevation\", \"WetMass\"])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f3baca-6172-416e-bde5-5db85fcf13e0",
   "metadata": {},
   "source": [
    "Instead of dropping rows where there are extreme crop yield values, we can also replace outlier values with a more sensible value such as the mean.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc441774-30f0-4d74-92ee-d4ecdda714f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_yield = gdf.loc[:, [\"Variety\", \"DryYield\"]].groupby([\"Variety\"]).mean()\n",
    "mean_yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d584f0-f3f1-4066-8fb3-6697fdf73bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_canola = gdf.loc[gdf[\"Variety\"] == \"43Y23 RR\", :]\n",
    "df_canola.loc[(df_canola[\"DryYield\"]-df_canola[\"DryYield\"].mean()).abs() > (3*df_canola[\"DryYield\"].std()), \"DryYield\"] = mean_yield.iloc[0, 0]\n",
    "\n",
    "df_wheat = gdf.loc[gdf[\"Variety\"] == \"Ninja\", :]\n",
    "df_wheat.loc[(df_wheat[\"DryYield\"]-df_wheat[\"DryYield\"].mean()).abs() > (3*df_wheat[\"DryYield\"].std()), \"DryYield\"] = mean_yield.iloc[1, 0]\n",
    "\n",
    "# combine filtered dfs\n",
    "gdf_replaced = pd.concat([df_canola, df_wheat], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9211f5b0-246f-4abe-9383-5cca6a91658e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(\n",
    "    data_frame=gdf_replaced, \n",
    "    x=\"DryYield\", \n",
    "    facet_col=\"Variety\", \n",
    "    marginal=\"box\", \n",
    "    hover_data=[\"DryYield\", \"Elevation\", \"WetMass\"])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53126590-bf57-4d24-a0b4-4edb8424e347",
   "metadata": {},
   "source": [
    "Looking at the wheat yield histogram we can see there are a large number of zero or close to zero values. This is another strange artefact in the distribution of our data values. Are zero crop yield values actually no crop yield from the plant or a source of measurement error or other noise? If the latter, we should remove these noisy values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819b0bed-b7dc-4bbe-9000-68042b9140b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_canola = gdf_clean.loc[gdf_clean[\"Variety\"] == \"43Y23 RR\", :]\n",
    "print(f\"The number of canola observations with yield values of zero or less is: {(df_canola['DryYield'] <= 0).sum()}\")\n",
    "df_wheat = gdf_clean.loc[gdf_clean[\"Variety\"] == \"Ninja\", :]\n",
    "print(f\"The number of wheat observations with yield values of zero or less is: {(df_wheat['DryYield'] <= 0).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb825152-34c1-4879-a8a0-4d301cc765cf",
   "metadata": {},
   "source": [
    "Above, when setting the outlier values to their mean value, we demonstrated how can use `loc` on the left hand side of an expression to determine which values are set. \n",
    "\n",
    "Here, all rows in `df_canola` with a value more / less than three standard deviations from the mean are set to the mean value.\n",
    "\n",
    "`df_canola.loc[(df_canola[\"DryYield\"]-df_canola[\"DryYield\"].mean()).abs() > (3*df_canola[\"DryYield\"].std()), \"DryYield\"] = mean_yield.iloc[0, 0]`\n",
    "\n",
    "#### Recap quiz\n",
    "\n",
    "**We're going to drop zero `DryYield` values as these values are noisy. Can you use a *selection by condition* operation to subset the `GeoDataFrame` `gdf_clean` to select only rows where `DryYield` is greater than zero?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a129187-56a8-4d9a-8163-387c60f09b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add code here ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8813137-2457-408d-809f-f64441c13795",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>answer</b></summary>\n",
    "\n",
    "```{python}\n",
    "print(\"Shape of DataFrame before dropping zero yield values:\")\n",
    "print(gdf_clean.shape)\n",
    "gdf_dropped_zero = gdf_clean.loc[gdf_clean[\"DryYield\"] > 0, :]\n",
    "print(\"Shape of DataFrame after dropping zero yield values:\")\n",
    "print(gdf_dropped_zero.shape)\n",
    "```\n",
    "</details>\n",
    "\n",
    "<p></p>\n",
    "\n",
    "**Can you generate a histogram visualising the distribution of `DryYield` values after dropping zero values? Use the `Variety` column to generate faceted subplots for each wheat and canola.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba259e2-0878-4af9-b8b9-ee88593c6010",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ADD CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8f487d-eef0-4215-a5fb-0b38d297d3f2",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>answer</b></summary>\n",
    "\n",
    "```{python}\n",
    "fig = px.histogram(\n",
    "    data_frame=gdf_dropped_zero, \n",
    "    x=\"DryYield\", \n",
    "    facet_col=\"Variety\", \n",
    "    marginal=\"box\", \n",
    "    hover_data=[\"DryYield\", \"Elevation\", \"WetMass\"])\n",
    "fig.show()\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b55652-a1d9-411c-83b4-8c9d19f791bf",
   "metadata": {},
   "source": [
    "After removing zero values the distribution of our crop yield values should look more sensible and relatively normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548521f8-21e1-42e1-aa73-0e34babc6f8b",
   "metadata": {},
   "source": [
    "### 2D histograms\n",
    "\n",
    "We can use 2D histograms or density heatmaps to look at the distribution of two variables together. 2D hisograms are a useful complement to scatter plots when you have a large number of observations. Here, colour is used to represent the distribution of data values as opposed to the height of rectangular bars on a histogram.\n",
    "\n",
    "Let's create 2D histograms to visualise the relationship between vegetation indices and canola crop yield. Note, you'll need to have completed the recap quiz above to generate `gdf_dropped_zero`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8621215a-4996-432a-8a60-c5dc72ff4b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.density_heatmap(\n",
    "    data_frame=gdf_dropped_zero.loc[gdf_dropped_zero[\"Variety\"] == \"43Y23 RR\", :], \n",
    "    x=\"DryYield\", \n",
    "    y=\"gndvi\", \n",
    "    marginal_x=\"box\", \n",
    "    marginal_y=\"box\",\n",
    "    range_y=[0.4, 0.8])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24624ba2-fc09-4a99-bf2d-3b0925913ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.density_heatmap(\n",
    "    data_frame=gdf_dropped_zero.loc[gdf_dropped_zero[\"Variety\"] == \"43Y23 RR\", :], \n",
    "    x=\"DryYield\", \n",
    "    y=\"ndyi\", \n",
    "    marginal_x=\"box\", \n",
    "    marginal_y=\"box\",\n",
    "    range_y=[0.1, 0.5])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077f4f8d-df69-46b4-b38f-ba7bb66ca259",
   "metadata": {},
   "source": [
    "### Violin plots\n",
    "\n",
    "One of the limits of using histograms to visualise distributions is the size of the bins affects the distribution of data values. An alternative approach to visualising a distribution is to use a violin plot. \n",
    "\n",
    "Violin plots use density and box plots to visualise distributions, which look similar to violins. The density is the probability of an observation taking on a certain value and is plotted as a smooth curve. Areas where the curve is fatter indicate a higher probability that an observation will take that value. Box plots display the 25th, 50th, and 75th percentile values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65946cff-9ec5-4245-ba54-b31df6582d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.violin(\n",
    "    gdf_dropped_zero, \n",
    "    y=\"DryYield\", \n",
    "    x=\"Variety\", \n",
    "    color=\"Variety\", \n",
    "    box=True, \n",
    "    points=\"outliers\", \n",
    "    hover_data=[\"DryYield\", \"gndvi\"])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb02aff3-7b3d-4f61-b776-92515687baeb",
   "metadata": {},
   "source": [
    "#### Recap quiz\n",
    "\n",
    "**Can you create violin plots to visualise the GNDVI and NDYI values for each crop type?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad7dcd0-6549-4f3d-84c2-bd3a62a81d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ADD GNDVI VIOLIN PLOT CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dd0eb8-908e-4582-becc-00639db9c1b3",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>answer</b></summary>\n",
    "    \n",
    "```{python}\n",
    "fig = px.violin(\n",
    "    gdf_dropped_zero, \n",
    "    y=\"gndvi\", \n",
    "    x=\"Variety\", \n",
    "    color=\"Variety\", \n",
    "    box=True, \n",
    "    points=\"outliers\", \n",
    "    hover_data=[\"DryYield\", \"gndvi\"])\n",
    "fig.show()\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cc3788-6922-4f7d-a08e-4e9b9be058bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ADD NDYI VIOLIN PLOT CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2884a90-e131-4499-88db-baaf9727cb30",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>answer</b></summary>\n",
    "    \n",
    "```{python}\n",
    "fig = px.violin(\n",
    "    gdf_dropped_zero, \n",
    "    y=\"ndyi\", \n",
    "    x=\"Variety\", \n",
    "    color=\"Variety\", \n",
    "    box=True, \n",
    "    points=\"outliers\", \n",
    "    hover_data=[\"DryYield\", \"ndyi\"])\n",
    "fig.show()\n",
    "```\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
